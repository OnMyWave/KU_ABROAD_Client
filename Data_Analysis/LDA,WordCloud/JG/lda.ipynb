{"cells":[{"cell_type":"markdown","metadata":{"id":"vjAvZi0fP-DO"},"source":["## **Install dependencies**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13230,"status":"ok","timestamp":1657717293089,"user":{"displayName":"‍이종근[ 학부휴학 / 산업경영공학부 ]","userId":"16271830293614672182"},"user_tz":-540},"id":"KCx4SPWoQL26","outputId":"a8d90ab3-b924-48fc-bb3d-00295e4cbdf1"},"outputs":[{"name":"stderr","output_type":"stream","text":["bash: line 1: apt-get: command not found\n","bash: line 2: apt-get: command not found\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: JPype1 in /Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages (1.4.0)\n","Requirement already satisfied: konlpy in /Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages (0.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages (from konlpy) (1.4.0)\n","Requirement already satisfied: lxml>=4.1.0 in /Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages (from konlpy) (4.9.1)\n","Requirement already satisfied: numpy>=1.6 in /Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages (from konlpy) (1.23.1)\n"]}],"source":["%%bash\n","apt-get update\n","apt-get install g++ openjdk-8-jdk python-dev python3-dev\n","pip3 install JPype1\n","pip3 install konlpy"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1657717293089,"user":{"displayName":"‍이종근[ 학부휴학 / 산업경영공학부 ]","userId":"16271830293614672182"},"user_tz":-540},"id":"p7doi754QQcD","outputId":"89692a8f-ae81-417a-9b99-f9949c9eb748"},"outputs":[{"name":"stdout","output_type":"stream","text":["env: JAVA_HOME=\"/usr/lib/jvm/java-8-openjdk-amd64\"\n"]}],"source":["%env JAVA_HOME \"/usr/lib/jvm/java-8-openjdk-amd64\""]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8283,"status":"ok","timestamp":1657717301370,"user":{"displayName":"‍이종근[ 학부휴학 / 산업경영공학부 ]","userId":"16271830293614672182"},"user_tz":-540},"id":"D-TFr82bQTYw","outputId":"1e05246e-332d-4466-fa70-7beb740bcd0c"},"outputs":[{"name":"stdout","output_type":"stream","text":["mecab-ko is already installed\n","mecab-ko-dic is already installed\n","mecab-python is already installed\n","Done.\n","Processing /tmp/mecab-python-0.996\n","  Preparing metadata (setup.py): started\n","  Preparing metadata (setup.py): finished with status 'done'\n","Building wheels for collected packages: mecab-python\n","  Building wheel for mecab-python (setup.py): started\n","  Building wheel for mecab-python (setup.py): finished with status 'done'\n","  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp38-cp38-macosx_11_0_arm64.whl size=5166 sha256=24226842f41b68a4f68ead1f4f452ae40a4c89fdbf839ca75c05e8e68becaaa3\n","  Stored in directory: /Users/onmywave/Library/Caches/pip/wheels/e3/88/e7/a947778cce3c142d5721c0629e05db7b09979d3a973277ec2f\n"]},{"name":"stderr","output_type":"stream","text":["  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\n"]},{"name":"stdout","output_type":"stream","text":["Failed to build mecab-python\n","Installing collected packages: mecab-python\n","  Attempting uninstall: mecab-python\n","    Found existing installation: mecab-python 0.996-ko-0.9.2\n","    Uninstalling mecab-python-0.996-ko-0.9.2:\n","      Successfully uninstalled mecab-python-0.996-ko-0.9.2\n","  Running setup.py install for mecab-python: started\n","  Running setup.py install for mecab-python: finished with status 'done'\n"]},{"name":"stderr","output_type":"stream","text":["  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\n"]},{"name":"stdout","output_type":"stream","text":["Successfully installed mecab-python-0.996-ko-0.9.2\n"]}],"source":["%%bash\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n","pip3 install /tmp/mecab-python-0.996"]},{"cell_type":"markdown","metadata":{"id":"mN1gpR1DQZ-R"},"source":["## **Example**"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1657717301371,"user":{"displayName":"‍이종근[ 학부휴학 / 산업경영공학부 ]","userId":"16271830293614672182"},"user_tz":-540},"id":"tn4pYvj1QT3c"},"outputs":[],"source":["import konlpy\n","from konlpy.tag import Kkma, Komoran, Hannanum, Okt\n","from konlpy.utils import pprint\n","from konlpy.tag import Mecab\n","from tqdm import tqdm\n","import re\n","import pickle\n","import pandas as pd\n","from collections import defaultdict, Counter"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LDHXz6EVSG-8"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1200/1200 [00:02<00:00, 568.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["[0.016s][warning][os,thread] Attempt to protect stack guard pages failed (0x0000000169aac000-0x0000000169ab8000).\n","[0.016s][warning][os,thread] Attempt to deallocate stack guard pages failed.\n"]},{"name":"stderr","output_type":"stream","text":["  7%|▋         | 83/1200 [00:21<02:46,  6.71it/s] "]}],"source":["\n","\n","# -*- coding: utf-8 -*-\n","\n","\n","\n","def clean_text(text):\n","    \"\"\"\n","    한글, 영문, 숫자만 남기고 제거한다.\n","    :param text:\n","    :return:\n","    \n","    \"\"\"\n","    text = text.replace(\".\", \" \").strip()\n","    text = text.replace(\"·\", \" \").strip()\n","    pattern = '[^ ㄱ-ㅣ가-힣|0-9|a-zA-Z]+'\n","    text = re.sub(pattern=pattern, repl='', string=text)\n","    return text\n","\n","\n","def get_nouns(tokenizer, sentence):\n","    \"\"\"\n","    단어의 길이가 2이상인 일반명사(NNG), 고유명사(NNP), 외국어(SL)만을 반환한다.\n","    :param tokenizer:\n","    :param sentence:\n","    :return:\n","    \"\"\"\n","    tagged = tokenizer.pos(sentence)\n","    nouns = [s for s, t in tagged if t in ['SL', 'NNG', 'NNP'] and len(s) > 1]\n","    return nouns\n","\n","\n","def delete_stopwords(processed_data):\n","    \"\"\"\n","    불용어 처리\n","    \"\"\"\n","    data = []\n","    stopwords = ['고려','대학교','안녕','경우','학교','교환','과목','나라','시간','한국','정도','절차',\n","                 '작성','신청','대부분','경험','사용','학생','생각','진행','가능','관련','확인']\n","    for doc in processed_data:\n","      word_list = [x for x in doc if x not in stopwords]\n","      data.append(word_list)\n","\n","    return data\n","\n","\n","def tokenize(i,df, tokenization):\n","    tokenizer = tokenization()\n","    processed_data = []\n","    \n","    for sent in tqdm(df[i]):\n","        sentence = clean_text(sent.replace('\\n', '').strip())\n","        processed_data.append(get_nouns(tokenizer, sentence))\n","    return processed_data\n","\n","def get_nouns_for_okt(tokenizer, sentence):\n","    \"\"\"\n","    okt를 위한 method\n","    :return:\n","    noun\n","    \"\"\"\n","    tagged = tokenizer.pos(sentence)\n","    nouns = [s for s, t in tagged if t =='Noun' and len(s) > 1]\n","    return nouns\n","  \n","def tokenize_for_okt(i,df, tokenization):\n","    tokenizer = Okt()\n","    processed_data = []\n","    \n","    for sent in tqdm(df[i]):\n","        sentence = clean_text(sent.replace('\\n', '').strip())\n","        processed_data.append(get_nouns_for_okt(tokenizer, sentence))\n","    return processed_data\n","\n","\n","          \n","if __name__ == '__main__':\n","    \n","    data = pd.read_excel('data.xlsx')\n","    word_list = lambda x : [word for sublist in x for word in sublist ]\n","    words = []\n","\n","    processed_data1 = []\n","    processed_data2 = []\n","    processed_data3 = []\n","\n","    for i in range(1,10):\n","      data1 = tokenize(i,data,Mecab) \n","      data1 = delete_stopwords(processed_data1)\n","      processed_data1.append(word_list(data1))\n","\n","      data2 = tokenize(i,data,Kkma) \n","      data2 = delete_stopwords(processed_data2)\n","      processed_data2.append(word_list(data2))\n","\n","      data3 = tokenize_for_okt(i,data,Okt) \n","      data3 = delete_stopwords(processed_data3)\n","      processed_data3.append(word_list(data3))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6dt7Pf55swbk"},"outputs":[],"source":["import pickle\n","with open('list1.txt', 'wb') as f:\n","  pickle.dump(processed_data1, f)\n","with open('list2.txt', 'wb') as f:\n","  pickle.dump(processed_data2, f)\n","with open('list3.txt', 'wb') as f:\n","  pickle.dump(processed_data3, f)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"-TCQvUyvp_jS"},"outputs":[{"ename":"RuntimeError","evalue":"Compiled extensions are unavailable. If you've installed from a package, ask the package maintainer to include compiled extensions. If you're building Gensim from source yourself, install Cython and a C compiler, and then run `python setup.py build_ext --inplace` to retry. ","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","File \u001b[0;32m~/miniforge3/envs/env/lib/python3.8/site-packages/gensim/matutils.py:1353\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1353\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpora\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_mmreader\u001b[39;00m \u001b[39mimport\u001b[39;00m MmReader  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n","\u001b[0;31mImportError\u001b[0m: dlopen(/Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages/gensim/corpora/_mmreader.cpython-38-darwin.so, 0x0002): tried: '/Users/onmywave/miniforge3/envs/env/lib/python3.8/site-packages/gensim/corpora/_mmreader.cpython-38-darwin.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m/Users/onmywave/Desktop/Github/Datathon/LDA/JG/lda.ipynb 셀 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/onmywave/Desktop/Github/Datathon/LDA/JG/lda.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mldamodel\u001b[39;00m \u001b[39mimport\u001b[39;00m LdaModel\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/onmywave/Desktop/Github/Datathon/LDA/JG/lda.ipynb#ch0000008?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m CoherenceMetric\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/onmywave/Desktop/Github/Datathon/LDA/JG/lda.ipynb#ch0000008?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m corpora\n","File \u001b[0;32m~/miniforge3/envs/env/lib/python3.8/site-packages/gensim/__init__.py:11\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m parsing, corpora, matutils, interfaces, models, similarities, utils  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m     14\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m'\u001b[39m\u001b[39mgensim\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m logger\u001b[39m.\u001b[39mhandlers:  \u001b[39m# To ensure reload() doesn't add another one\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/env/lib/python3.8/site-packages/gensim/corpora/__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mThis package contains implementations of various streaming corpus I/O format.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# bring corpus classes directly into package namespace, to save some typing\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mindexedcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m IndexedCorpus  \u001b[39m# noqa:F401 must appear before the other classes\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmmcorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m MmCorpus  \u001b[39m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbleicorpus\u001b[39;00m \u001b[39mimport\u001b[39;00m BleiCorpus  \u001b[39m# noqa:F401\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/env/lib/python3.8/site-packages/gensim/corpora/indexedcorpus.py:14\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m interfaces, utils\n\u001b[1;32m     16\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mIndexedCorpus\u001b[39;00m(interfaces\u001b[39m.\u001b[39mCorpusABC):\n","File \u001b[0;32m~/miniforge3/envs/env/lib/python3.8/site-packages/gensim/interfaces.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39m\"\"\"Basic interfaces used across the whole Gensim package.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[39mThese interfaces are used for building corpora, model transformation and similarity queries.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m \u001b[39mimport\u001b[39;00m utils, matutils\n\u001b[1;32m     22\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mCorpusABC\u001b[39;00m(utils\u001b[39m.\u001b[39mSaveLoad):\n","File \u001b[0;32m~/miniforge3/envs/env/lib/python3.8/site-packages/gensim/matutils.py:1355\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mgensim\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcorpora\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_mmreader\u001b[39;00m \u001b[39mimport\u001b[39;00m MmReader  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m   1354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m-> 1355\u001b[0m     \u001b[39mraise\u001b[39;00m utils\u001b[39m.\u001b[39mNO_CYTHON\n","\u001b[0;31mRuntimeError\u001b[0m: Compiled extensions are unavailable. If you've installed from a package, ask the package maintainer to include compiled extensions. If you're building Gensim from source yourself, install Cython and a C compiler, and then run `python setup.py build_ext --inplace` to retry. "]}],"source":["from gensim.models.ldamodel import LdaModel\n","from gensim.models.callbacks import CoherenceMetric\n","from gensim import corpora\n","from gensim.models.callbacks import PerplexityMetric"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JmtLZcZQHUhj"},"outputs":[],"source":["Mecab_nouns = word_list(processed_data1)\n","Kkma_nouns = word_list(processed_data2)\n","Okt_nouns = word_list(processed_data3)\n","\n","print(processed_data3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrH5gRRFrUkT"},"outputs":[],"source":["!pip install pyLDAvis"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vg3Xf3qOsxqT"},"outputs":[],"source":["import pickle\n","import pyLDAvis.gensim_models as gensimvis\n","import pyLDAvis\n","from gensim.models.coherencemodel import CoherenceModel\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rdNd_T4hNQ6j"},"outputs":[],"source":["# Mecab, Kkma, Okt 비교\n","Mecab_Counter = Counter(Mecab_nouns)\n","Kkma_Counter = Counter(Kkma_nouns)\n","Okt_Counter = Counter(Okt_nouns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1bYQ5bcsOAYf"},"outputs":[],"source":["print(Mecab_Counter)\n","print(Kkma_Counter)\n","print(Okt_Counter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P9DvFK3eq5EP"},"outputs":[],"source":["dictionary = corpora.Dictionary(processed_data1)\n","dictionary.filter_extremes(no_below=2, no_above=0.5)\n","corpus = [dictionary.doc2bow(text) for text in processed_data1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-l-bwcTrD08"},"outputs":[],"source":["num_topics = 8\n","chunksize = 2000\n","passes = 8\n","iterations = 400\n","eval_every = None\n","\n","temp = dictionary[0]\n","id2word = dictionary.id2token\n","\n","model = LdaModel(\n","    corpus=corpus,\n","    id2word=id2word,\n","    chunksize=chunksize,\n","    alpha='auto',\n","    eta='auto',\n","    iterations=iterations,\n","    num_topics=num_topics,\n","    passes=passes,\n","    eval_every=eval_every\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zdi4CMflrM5L"},"outputs":[],"source":["top_topics = model.top_topics(corpus) #, num_words=20)\n","\n","# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n","avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n","print('Average topic coherence: %.4f.' % avg_topic_coherence)\n","\n","from pprint import pprint\n","pprint(top_topics)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y6AWGvEjsz0G"},"outputs":[],"source":["lda_visualization = gensimvis.prepare(model, corpus, dictionary, sort_topics=False)\n","pyLDAvis.save_html(lda_visualization, 'f.html')"]}],"metadata":{"colab":{"name":"lda.ipynb","provenance":[{"file_id":"1IHqCicmaDHIJtpywlGFYD9wS-zQ-J-s3","timestamp":1657047209295}]},"kernelspec":{"display_name":"Python 3.8.5 64-bit ('env': conda)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.13"},"vscode":{"interpreter":{"hash":"6a5b60688788e6e458da1da836120a4055e669fe2b4e18fc6595f7a71c2d91dd"}}},"nbformat":4,"nbformat_minor":0}
